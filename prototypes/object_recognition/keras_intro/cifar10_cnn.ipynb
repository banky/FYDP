{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "(32, 32, 3)\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.8653 - acc: 0.3135 - val_loss: 1.6499 - val_acc: 0.4130\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5805 - acc: 0.4242 - val_loss: 1.3623 - val_acc: 0.5116\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4610 - acc: 0.4681 - val_loss: 1.4217 - val_acc: 0.5037\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3802 - acc: 0.5029 - val_loss: 1.2115 - val_acc: 0.5698\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3094 - acc: 0.5325 - val_loss: 1.1215 - val_acc: 0.6040\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2534 - acc: 0.5542 - val_loss: 1.1554 - val_acc: 0.5902\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2022 - acc: 0.5710 - val_loss: 1.1595 - val_acc: 0.5945\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1610 - acc: 0.5851 - val_loss: 1.0034 - val_acc: 0.6449\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1261 - acc: 0.6016 - val_loss: 1.0638 - val_acc: 0.6215\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1047 - acc: 0.6094 - val_loss: 1.0675 - val_acc: 0.6323\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0735 - acc: 0.6216 - val_loss: 0.9665 - val_acc: 0.6575\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0485 - acc: 0.6285 - val_loss: 0.9467 - val_acc: 0.6718\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0321 - acc: 0.6369 - val_loss: 0.8984 - val_acc: 0.6871\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0030 - acc: 0.6468 - val_loss: 0.9583 - val_acc: 0.6668\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9876 - acc: 0.6535 - val_loss: 0.8648 - val_acc: 0.6954\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9662 - acc: 0.6602 - val_loss: 0.8949 - val_acc: 0.6836\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9577 - acc: 0.6628 - val_loss: 0.9473 - val_acc: 0.6775\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9446 - acc: 0.6689 - val_loss: 0.9077 - val_acc: 0.6838\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9322 - acc: 0.6734 - val_loss: 0.8584 - val_acc: 0.7038\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9224 - acc: 0.6771 - val_loss: 0.8702 - val_acc: 0.7052\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9140 - acc: 0.6820 - val_loss: 0.8178 - val_acc: 0.7192\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9040 - acc: 0.6861 - val_loss: 0.7917 - val_acc: 0.7265\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9017 - acc: 0.6875 - val_loss: 0.7979 - val_acc: 0.7276\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8892 - acc: 0.6924 - val_loss: 0.8306 - val_acc: 0.7192\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8842 - acc: 0.6934 - val_loss: 0.8308 - val_acc: 0.7175\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8767 - acc: 0.6989 - val_loss: 0.7977 - val_acc: 0.7250\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8717 - acc: 0.6977 - val_loss: 0.8156 - val_acc: 0.7177\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8666 - acc: 0.7020 - val_loss: 0.7939 - val_acc: 0.7274\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8671 - acc: 0.7011 - val_loss: 0.7527 - val_acc: 0.7397\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8594 - acc: 0.7058 - val_loss: 0.7608 - val_acc: 0.7381\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8531 - acc: 0.7077 - val_loss: 0.7678 - val_acc: 0.7376\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8461 - acc: 0.7078 - val_loss: 0.7611 - val_acc: 0.7390\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8453 - acc: 0.7116 - val_loss: 0.7270 - val_acc: 0.7566\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8435 - acc: 0.7121 - val_loss: 0.7445 - val_acc: 0.7417\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8384 - acc: 0.7146 - val_loss: 0.7313 - val_acc: 0.7510\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8365 - acc: 0.7156 - val_loss: 0.7027 - val_acc: 0.7589\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8318 - acc: 0.7152 - val_loss: 0.7489 - val_acc: 0.7481\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8230 - acc: 0.7182 - val_loss: 0.7042 - val_acc: 0.7630\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8246 - acc: 0.7184 - val_loss: 0.7391 - val_acc: 0.7607\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8292 - acc: 0.7186 - val_loss: 0.7989 - val_acc: 0.7295\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8255 - acc: 0.7164 - val_loss: 0.7277 - val_acc: 0.7533\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8264 - acc: 0.7188 - val_loss: 0.8316 - val_acc: 0.7206\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8211 - acc: 0.7219 - val_loss: 0.7038 - val_acc: 0.7637\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8218 - acc: 0.7230 - val_loss: 0.7311 - val_acc: 0.7563\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8142 - acc: 0.7230 - val_loss: 0.6998 - val_acc: 0.7617\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8066 - acc: 0.7267 - val_loss: 0.7305 - val_acc: 0.7546\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8147 - acc: 0.7228 - val_loss: 0.7821 - val_acc: 0.7371\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8028 - acc: 0.7271 - val_loss: 0.7304 - val_acc: 0.7580\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8085 - acc: 0.7253 - val_loss: 0.7623 - val_acc: 0.7432\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8061 - acc: 0.7272 - val_loss: 0.7594 - val_acc: 0.7530\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8092 - acc: 0.7274 - val_loss: 0.7257 - val_acc: 0.7570\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8042 - acc: 0.7279 - val_loss: 0.7610 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7955 - acc: 0.7299 - val_loss: 0.7609 - val_acc: 0.7490\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8042 - acc: 0.7289 - val_loss: 0.7584 - val_acc: 0.7545\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7970 - acc: 0.7300 - val_loss: 0.7135 - val_acc: 0.7635\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8016 - acc: 0.7301 - val_loss: 0.8398 - val_acc: 0.7318\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7945 - acc: 0.7320 - val_loss: 0.6791 - val_acc: 0.7725\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7978 - acc: 0.7307 - val_loss: 0.6939 - val_acc: 0.7691\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7945 - acc: 0.7321 - val_loss: 0.7755 - val_acc: 0.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7930 - acc: 0.7342 - val_loss: 0.6837 - val_acc: 0.7769\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7910 - acc: 0.7320 - val_loss: 0.7123 - val_acc: 0.7626\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7888 - acc: 0.7314 - val_loss: 0.7214 - val_acc: 0.7608\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7930 - acc: 0.7319 - val_loss: 0.7258 - val_acc: 0.7551\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7850 - acc: 0.7368 - val_loss: 0.7879 - val_acc: 0.7435\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7905 - acc: 0.7340 - val_loss: 0.6721 - val_acc: 0.7718\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7903 - acc: 0.7359 - val_loss: 0.7428 - val_acc: 0.7584\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7909 - acc: 0.7339 - val_loss: 0.7213 - val_acc: 0.7645\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7903 - acc: 0.7366 - val_loss: 0.6690 - val_acc: 0.7771\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7903 - acc: 0.7343 - val_loss: 0.7956 - val_acc: 0.7390\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7892 - acc: 0.7346 - val_loss: 0.7120 - val_acc: 0.7821\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7843 - acc: 0.7363 - val_loss: 0.7436 - val_acc: 0.7558\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7848 - acc: 0.7343 - val_loss: 0.7433 - val_acc: 0.7539\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7848 - acc: 0.7365 - val_loss: 0.7062 - val_acc: 0.7668\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7836 - acc: 0.7366 - val_loss: 0.7654 - val_acc: 0.7474\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7837 - acc: 0.7377 - val_loss: 0.7190 - val_acc: 0.7601\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7857 - acc: 0.7362 - val_loss: 0.7473 - val_acc: 0.7620\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7905 - acc: 0.7356 - val_loss: 0.8074 - val_acc: 0.7299\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7886 - acc: 0.7371 - val_loss: 0.7142 - val_acc: 0.7621\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7858 - acc: 0.7380 - val_loss: 0.7673 - val_acc: 0.7584\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7907 - acc: 0.7370 - val_loss: 0.7562 - val_acc: 0.7483\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7909 - acc: 0.7371 - val_loss: 0.7544 - val_acc: 0.7485\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7902 - acc: 0.7361 - val_loss: 0.6591 - val_acc: 0.7807\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7900 - acc: 0.7358 - val_loss: 0.6997 - val_acc: 0.7702\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7829 - acc: 0.7390 - val_loss: 0.6787 - val_acc: 0.7771\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7811 - acc: 0.7413 - val_loss: 0.7277 - val_acc: 0.7626\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7916 - acc: 0.7370 - val_loss: 0.7324 - val_acc: 0.7630\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7973 - acc: 0.7353 - val_loss: 0.6876 - val_acc: 0.7806\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7885 - acc: 0.7381 - val_loss: 0.6697 - val_acc: 0.7817\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7893 - acc: 0.7386 - val_loss: 0.6673 - val_acc: 0.7759\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7888 - acc: 0.7356 - val_loss: 0.6851 - val_acc: 0.7772\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7868 - acc: 0.7360 - val_loss: 0.7448 - val_acc: 0.7512\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7889 - acc: 0.7399 - val_loss: 0.7058 - val_acc: 0.7688\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7977 - acc: 0.7354 - val_loss: 0.7532 - val_acc: 0.7483\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7949 - acc: 0.7384 - val_loss: 0.7986 - val_acc: 0.7302\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7921 - acc: 0.7370 - val_loss: 0.7329 - val_acc: 0.7595\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7951 - acc: 0.7343 - val_loss: 0.7742 - val_acc: 0.7441\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7900 - acc: 0.7390 - val_loss: 0.6976 - val_acc: 0.7716\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.8005 - acc: 0.7350 - val_loss: 0.7677 - val_acc: 0.7460\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.7941 - acc: 0.7398 - val_loss: 0.7237 - val_acc: 0.7625\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8048 - acc: 0.7368 - val_loss: 0.6822 - val_acc: 0.7709\n",
      "Saved trained model at C:\\Users\\Banky\\Development\\FYDP\\prototypes\\object_recognition\\keras_intro\\saved_models\\keras_cifar10_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "print(x_train.shape[1:])\n",
    "nb_train_samples = int(x_train.shape[0] / 32) + 1\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch = nb_train_samples,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 20s 0us/step\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "(32, 32, 3)\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.8554 - acc: 0.3157 - val_loss: 1.6161 - val_acc: 0.4196\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5748 - acc: 0.4241 - val_loss: 1.3587 - val_acc: 0.5047\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4482 - acc: 0.4759 - val_loss: 1.3103 - val_acc: 0.5294\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3643 - acc: 0.5100 - val_loss: 1.2009 - val_acc: 0.5666\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2888 - acc: 0.5377 - val_loss: 1.0922 - val_acc: 0.6171\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2326 - acc: 0.5590 - val_loss: 1.1085 - val_acc: 0.6054\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1880 - acc: 0.5789 - val_loss: 1.1751 - val_acc: 0.5812\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1470 - acc: 0.5935 - val_loss: 1.2662 - val_acc: 0.5827\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1147 - acc: 0.6046 - val_loss: 0.9995 - val_acc: 0.6461\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0814 - acc: 0.6179 - val_loss: 0.9845 - val_acc: 0.6524\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0548 - acc: 0.6315 - val_loss: 0.9602 - val_acc: 0.6688\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0277 - acc: 0.6371 - val_loss: 0.8937 - val_acc: 0.6905\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0076 - acc: 0.6457 - val_loss: 1.1468 - val_acc: 0.6244\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9877 - acc: 0.6540 - val_loss: 0.8512 - val_acc: 0.7034\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9743 - acc: 0.6593 - val_loss: 0.8519 - val_acc: 0.7085\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9534 - acc: 0.6687 - val_loss: 0.8045 - val_acc: 0.7200\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9427 - acc: 0.6731 - val_loss: 0.9140 - val_acc: 0.6792\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9279 - acc: 0.6790 - val_loss: 0.7890 - val_acc: 0.7269\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9212 - acc: 0.6818 - val_loss: 0.8462 - val_acc: 0.7162\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9029 - acc: 0.6873 - val_loss: 0.8277 - val_acc: 0.7154\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8924 - acc: 0.6891 - val_loss: 0.7881 - val_acc: 0.7307\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8836 - acc: 0.6941 - val_loss: 0.7558 - val_acc: 0.7440\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8758 - acc: 0.6971 - val_loss: 0.7809 - val_acc: 0.7359\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8722 - acc: 0.6999 - val_loss: 0.7767 - val_acc: 0.7384\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8588 - acc: 0.7045 - val_loss: 0.8100 - val_acc: 0.7256\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8618 - acc: 0.7042 - val_loss: 0.7968 - val_acc: 0.7311\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8540 - acc: 0.7072 - val_loss: 0.7444 - val_acc: 0.7460\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8479 - acc: 0.7090 - val_loss: 0.7540 - val_acc: 0.7550\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8375 - acc: 0.7129 - val_loss: 0.7858 - val_acc: 0.7347\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8388 - acc: 0.7136 - val_loss: 0.7482 - val_acc: 0.7444\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8356 - acc: 0.7143 - val_loss: 0.7872 - val_acc: 0.7333\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8269 - acc: 0.7158 - val_loss: 0.7916 - val_acc: 0.7346\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8235 - acc: 0.7194 - val_loss: 0.8092 - val_acc: 0.7379\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8209 - acc: 0.7188 - val_loss: 0.7519 - val_acc: 0.7491\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8200 - acc: 0.7210 - val_loss: 0.8196 - val_acc: 0.7354\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8235 - acc: 0.7203 - val_loss: 0.6929 - val_acc: 0.7677\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8187 - acc: 0.7218 - val_loss: 0.7736 - val_acc: 0.7397\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8081 - acc: 0.7252 - val_loss: 0.7377 - val_acc: 0.7522\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8098 - acc: 0.7246 - val_loss: 0.7868 - val_acc: 0.7332\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8060 - acc: 0.7263 - val_loss: 0.7795 - val_acc: 0.7409\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8034 - acc: 0.7285 - val_loss: 0.7175 - val_acc: 0.7613\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8028 - acc: 0.7290 - val_loss: 0.6780 - val_acc: 0.7780\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7988 - acc: 0.7312 - val_loss: 0.7294 - val_acc: 0.7523\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7962 - acc: 0.7297 - val_loss: 0.7031 - val_acc: 0.7694\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7913 - acc: 0.7320 - val_loss: 0.7412 - val_acc: 0.7521\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7939 - acc: 0.7298 - val_loss: 0.8226 - val_acc: 0.7257\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7890 - acc: 0.7327 - val_loss: 0.7412 - val_acc: 0.7508\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7918 - acc: 0.7322 - val_loss: 0.7344 - val_acc: 0.7617\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7884 - acc: 0.7336 - val_loss: 0.7347 - val_acc: 0.7596\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7931 - acc: 0.7344 - val_loss: 0.7927 - val_acc: 0.7382\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7916 - acc: 0.7313 - val_loss: 0.7769 - val_acc: 0.7402\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7901 - acc: 0.7352 - val_loss: 0.7373 - val_acc: 0.7506\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7825 - acc: 0.7380 - val_loss: 0.7198 - val_acc: 0.7614\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7825 - acc: 0.7372 - val_loss: 0.6869 - val_acc: 0.7705\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7781 - acc: 0.7387 - val_loss: 0.7624 - val_acc: 0.7424\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7851 - acc: 0.7368 - val_loss: 0.7955 - val_acc: 0.7358\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7823 - acc: 0.7378 - val_loss: 0.6803 - val_acc: 0.7730\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7848 - acc: 0.7372 - val_loss: 0.7716 - val_acc: 0.7470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7763 - acc: 0.7395 - val_loss: 0.7187 - val_acc: 0.7680\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7783 - acc: 0.7371 - val_loss: 0.7462 - val_acc: 0.7563\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7811 - acc: 0.7372 - val_loss: 0.7604 - val_acc: 0.7497\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7749 - acc: 0.7411 - val_loss: 0.6584 - val_acc: 0.7804\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7869 - acc: 0.7379 - val_loss: 0.7605 - val_acc: 0.7599\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7775 - acc: 0.7377 - val_loss: 0.7099 - val_acc: 0.7623\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7837 - acc: 0.7359 - val_loss: 0.7847 - val_acc: 0.7506\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7787 - acc: 0.7395 - val_loss: 0.7207 - val_acc: 0.7624\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7787 - acc: 0.7403 - val_loss: 0.7194 - val_acc: 0.7657\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7790 - acc: 0.7380 - val_loss: 0.6788 - val_acc: 0.7756\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7811 - acc: 0.7389 - val_loss: 0.6770 - val_acc: 0.7776\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7843 - acc: 0.7375 - val_loss: 0.6900 - val_acc: 0.7789\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7758 - acc: 0.7426 - val_loss: 0.7156 - val_acc: 0.7616\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7827 - acc: 0.7397 - val_loss: 0.6485 - val_acc: 0.7832\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7718 - acc: 0.7416 - val_loss: 0.6494 - val_acc: 0.7829\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7824 - acc: 0.7416 - val_loss: 0.7826 - val_acc: 0.7529\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7791 - acc: 0.7414 - val_loss: 0.7471 - val_acc: 0.7624\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7809 - acc: 0.7416 - val_loss: 0.9056 - val_acc: 0.7036\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7858 - acc: 0.7392 - val_loss: 0.7676 - val_acc: 0.7466\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7798 - acc: 0.7420 - val_loss: 0.8166 - val_acc: 0.7483\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7867 - acc: 0.7396 - val_loss: 0.6657 - val_acc: 0.7787\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7791 - acc: 0.7418 - val_loss: 0.7430 - val_acc: 0.7531\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7843 - acc: 0.7404 - val_loss: 0.6742 - val_acc: 0.7775\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7852 - acc: 0.7392 - val_loss: 0.6858 - val_acc: 0.7844\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7891 - acc: 0.7380 - val_loss: 0.7904 - val_acc: 0.7413\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7944 - acc: 0.7384 - val_loss: 0.7823 - val_acc: 0.7473\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7841 - acc: 0.7416 - val_loss: 0.9711 - val_acc: 0.7285\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7813 - acc: 0.7412 - val_loss: 0.7216 - val_acc: 0.7647\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7921 - acc: 0.7390 - val_loss: 0.7107 - val_acc: 0.7629\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7961 - acc: 0.7369 - val_loss: 0.7513 - val_acc: 0.7571\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7950 - acc: 0.7360 - val_loss: 0.9246 - val_acc: 0.7094\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7962 - acc: 0.7361 - val_loss: 0.8482 - val_acc: 0.7204\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7977 - acc: 0.7353 - val_loss: 0.7232 - val_acc: 0.7620\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7981 - acc: 0.7369 - val_loss: 0.7643 - val_acc: 0.7656\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.7939 - acc: 0.7372 - val_loss: 0.7339 - val_acc: 0.7580\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8015 - acc: 0.7344 - val_loss: 0.6866 - val_acc: 0.7827\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8041 - acc: 0.7334 - val_loss: 0.9520 - val_acc: 0.7042\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8081 - acc: 0.7336 - val_loss: 0.6839 - val_acc: 0.7766\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8073 - acc: 0.7337 - val_loss: 0.7171 - val_acc: 0.7580\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8121 - acc: 0.7347 - val_loss: 0.9920 - val_acc: 0.7081\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8121 - acc: 0.7327 - val_loss: 0.6565 - val_acc: 0.7867\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8152 - acc: 0.7317 - val_loss: 0.7018 - val_acc: 0.7689\n",
      "Saved trained model at /home/banky/Development/FYDP/prototypes/object_recognition/keras_intro/saved_models/keras_cifar10_trained_model.h5 \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "print(x_train.shape[1:])\n",
    "nb_train_samples = int(x_train.shape[0] / 32) + 1\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        steps_per_epoch = nb_train_samples,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
